The notebook contains the first Python proposal interface applied in the classification of body gestures.

The notebook has different sections:

1. Import the Python libraries
2. Create the directories to the folders (modify if using the repository)
3. Define the Python interface, for this two windows are created that use the 'PySimpleGUI' library. The interface allows: defining the number of classes to train and the number of images that define each class, extracting the keypoints using MoveNet, applying a classification algorithm and try the classification on real-time.
4. Each one of the classified new gestures are mapped to a sound. 
